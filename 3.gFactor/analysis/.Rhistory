mcmc_params$rc_alternating <- c(0,2,1,1,0,0)
#c_Hcor_S3 <- fit_meta_d_mcmc_groupCorr(c_nrsxs[1,],c_nrsxs[2,],mcmc_params)
#saveRDS(c_Hcor_S3,'rds_files/c_Hcor_S3.rds',compress=F);beep()
c_Hcor_S3 <- readRDS('rds_files/c_Hcor_S3.rds')
# Per-Protocol data #
# full <- fit_meta_d_mcmc_groupCorr(nrsx[1,],nrsx[2,],mcmc_params)
# 2AFC only (model test) #
#mcmc_params$response_conditional <- 0
#cor_2AFC <- fit_meta_d_mcmc_groupCorr(c_nrsxs[1,c(1,3,5)],c_nrsxs[2,c(1,3,5)],mcmc_params)
#saveRDS(cor_2AFC,'rds_files/cor_2AFC.rds',compress=F);beep()
#cor_2AFC <- readRDS('rds_files/cor_2AFC.rds')
# Matrix of sample plots
plotMat <- function(Hcor){
n_task <- NROW(Hcor$group_level)
rho_idx <- t(combn(1:n_task, 2))
rho_s <- Hcor$mcmc$samples$rho
rho_m <- Hcor$rho$mat
rho_hdi <- Hcor$mcmc$HDI$rho
par(mfrow=c(Ntask-1,Ntask-1), oma=c(0,3,3,0),mar=rep(1,4))
i<-0
for(x in (Ntask-1):1){
if(x<(Ntask-1)){
for(y in 1:((Ntask-1)-x)){
plot(0, type="n",axes=F,ann=F)
}
}
for(y in 1:x){ i<-i+1
#if(x==(n_task-1)){title <- names(tasks)[y+1];ann=T} else { ann=F }
hist(rho_s[,i],freq=F,breaks=50, ann=F,cex.axis=1) #,main=title)#main=colnames(rho_s)[i])#ann=F)#
#to plot probabilities rather than density: https://stackoverflow.com/a/17433446/7705626
abline(v=0,col=2, lwd=3, lty='dotted')
abline(v=rho_m[rho_idx[i,1],rho_idx[i,2]],col=1,lwd=2)
abline(v=rho_hdi[i,1],col=4, lwd=3, lty='dashed',lend=2)
abline(v=rho_hdi[i,2],col=4, lwd=3, lty='dashed',lend=2)
if(y==1){
mtext(tnames[n_task-x+1], line=-.7, side=3, outer=TRUE, at=grconvertX(0.5,'npc','nic'),cex=.7,font=2)
mtext(tnames[n_task-x], line=1, side=2, outer=TRUE, at=grconvertY(0.5,'npc','nic'),cex=.7,font=2) #mtext(names(tasks)[n_task-x], line=2, side=2,cex=.6) #
}
}
}
mtext('Posterior Densities on Correlations', line=1, side=3, outer=TRUE, cex=1,font=2)
}
#plotMat(c_Hcor_S0)
# Hierarchical Pooling ----
hPool <- function(H_cor,file_name){ #H_cor<-c_Hcor_S1;file_name<-'abc'
#correlation between domains vs within
#correlation between 2AFC and YN tasks vs between 2AFC tasks
# datasets
rhos <- r2z(H_cor$rho$mat)
HDIs <- r2z(H_cor$mcmc$HDI$rho)
#SEs <- (HDIs[,2]-HDIs[,1])/4
# idxs
AFC_idx <- which(names(tasks)%in%c('dots','gabor_2AFC','span_2AFC'))
YN_idx <- which(names(tasks)%in%c('gabor_YN','span_YN'))
V_idx <- which(names(tasks)%in%c('dots','gabor_YN','gabor_2AFC'))
M_idx <- which(names(tasks)%in%c('span_YN','span_2AFC'))
G_idx <- which(names(tasks)%in%c('gabor_YN','gabor_2AFC'))
B_idx <- which(names(tasks)%in%'breath')
# row and col idx pairs
effect_idxs <- list(#within task type
'AFC'=list(AFC_idx,AFC_idx),
'YN'=list(YN_idx,YN_idx),
#between task type
'YN_2AFC'=list(AFC_idx,YN_idx),
#within domain
'gabor'=list(G_idx,G_idx), #within task variant
'visual'=list(V_idx,V_idx),
'memory'=list(M_idx,M_idx), #within task variant
#between domain
'between_domains'=list(V_idx,M_idx),
'vis_b'=list(V_idx,B_idx), #not used
'mem_b'=list(M_idx,B_idx)) #not used
#selcted cors
selected_cors <- lapply(effect_idxs, function(x){ #x<-rc_idxs[['FC']]
sub_mat <- rhos[x[[1]],x[[2]]]
if(identical(x[[1]],x[[2]])){
sub_mat <- sub_mat[lower.tri(sub_mat)]
}
return(sub_mat)
#ses <- SEs[which((idx[,1]%in%x[[1]] & idx[,2]%in%x[[2]]) | (idx[,2]%in%x[[1]] & idx[,1]%in%x[[2]]))]
#cbind(rho=c(sub_mat),se=ses)
})
#concatenate within-domain effects
selected_cors <- c(selected_cors,list(within_domains = do.call('rbind',selected_cors[c('visual','memory')]),
task_variants = do.call('rbind',selected_cors[c('gabor','memory')])))
#mean differences
categories <- list(YN_2AFC=c('YN','AFC'),
YN2AFC_AFC=c('YN_2AFC','AFC'),
#task_variants=c('task_variants','within_domains'),
domains=c('between_domains','within_domains'))
stuff <- t(sapply(categories,function(x){ #x<-categories[[1]]
lower <- selected_cors[[x[1]]]
higher <- selected_cors[[x[2]]]
#ses <- c(lower[,'se'],higher[,'se'])
l_m <- round2(mean(lower)) #[,'rho']
h_m <- round2(mean(higher))
m <- r2z(h_m-l_m)
#SE <- sqrt(sum(ses^2))
z_SE <- round2(1/sqrt(nrow(H_cor$Mratio)-3))
SE <- sqrt((z_SE^2)*2)
H1 <- (h_m)/2
BF_inputs <- round2(c(m=m,SE=SE,H1=H1))
BF <- bfrr(sample_mean=BF_inputs['m'],sample_se=SE,sample_df=nrow(H_cor$Mratio)-1,
model="normal", mean=0, sd=BF_inputs['H1'], tail=1, criterion=3,
rr_interval=list(mean=c(0,0),sd=c(0,1)),precision=.01)
c(lower=x[1],higher=x[2],l_m=l_m,h_m=h_m,BF_inputs,BF=BF$BF,RR=BF$RR$sd)
}))
stuff[,3:8] <- round2(as.numeric(stuff[,3:8]))
#stuff[,'m'] <- paste0(stuff[,'m'],' (',stuff[,'SE'],')')
stuff[stuff[,'RR1']==0.01,'RR1'] <- '0'
stuff[stuff[,'RR2']==1,'RR2'] <- '>1'
stuff[,'RR1'] <- paste0('[',stuff[,'RR1'],' ,',stuff[,'RR2'],']')
stuff <- stuff[,-which(colnames(stuff)%in%c('SE','RR2'))]
return(stuff)
}
cat_s0 <- hPool(c_Hcor_S0,"S0_category_test.csv")
cat_s1 <- hPool(c_Hcor_S1,'s1_category_test.csv')
cat_s2 <- hPool(c_Hcor_S2,'s2_category_test.csv')
cat_s3 <- hPool(c_Hcor_S3,'s3_category_test.csv')
write.csv(cat_s0,'csv_files/s0_category_test.csv')
write.csv(cat_s1,'csv_files/s1_category_test.csv')
write.csv(cat_s2,'csv_files/s2_category_test.csv')
write.csv(cat_s3,'csv_files/s3_category_test.csv')
# Hierarchical Relibailities -----
#odd even splits
#pp_split <- splitData(tasks) #per-protocol
#Standard S0 Reliabilities
#c_rels_S0 <- h_rels$'20'
#c_rels_S0$breath <- relibility(1,c_split[,6,drop=F],3)
#saveRDS(c_rels_S0,'rds_files/c_rels_S0.rds')
c_rels_S0 <- readRDS('rds_files/c_rels_S0.rds')
#RS1 reliabilities
#c_rels_S1 <- relibility(1,c_split,3)
#saveRDS(c_rels_S1,'rds_files/c_rels_S1.rds')
c_rels_S1 <- readRDS('rds_files/c_rels_S1.rds')
#RS2 reliabilities
#c_rels_S2 <- relibility(2,c_split,3)
#saveRDS(c_rels_S2,'rds_files/c_rels_S2.rds')
c_rels_S2 <- readRDS('rds_files/c_rels_S2.rds')
#Examine convergence
rel_rhat <- rbind(s0=sapply(c_rels_S0,function(x){x$mcmc$rhat$full$mpsrf}),
s1=sapply(c_rels_S1,function(x){x$mcmc$rhat$full$mpsrf}),
s2=sapply(c_rels_S2,function(x){x$mcmc$rhat$full$mpsrf}))
# Correct Relibailities -----
#oops - names would be good
names(c_rels_S0) <- names(tasks)
names(c_rels_S1) <- names(tasks)
names(c_rels_S2) <- names(tasks)
# select tasks with highest M-ratio (do first)
c_rels_S3 <- c_rels_S0
c_rels_S3[c('gabor_2AFC','span_YN')] <- c_rels_S1[c('gabor_2AFC','span_YN')]
c_rels_S3['gabor_YN'] <- c_rels_S2['gabor_YN']
# select 2AFC tasks
c_rels_S1[AFC] <- c_rels_S0[AFC]
c_rels_S2[AFC] <- c_rels_S0[AFC]
# get hrels in correct format
relList <- function(rels){
rel_l <- t(rbind(r=sapply(rels,function(x){x$rho$list}),
sapply(rels,function(x){x$mcmc$HDI$rho[1,]})))
round2(sb(rel_l))
}
rels_h <- list(M_ratio = relList(c_rels_S0),
M_ratio_rS1 = relList(c_rels_S1),
M_ratio_rS2 = relList(c_rels_S2),
h_mr = relList(c_rels_S3))
# Hierarchical BFs ---------
Hcor <- function(cors,rels){ # cors<-c_Hcor_S3; rels<-rels_h[[3]]
ntask <- ncol(cors$d1)
# combined reliabilities
H1s <- ( rels[idx[,1],'r'] * rels[idx[,2],'r'] ) **.5 /2
# actual correlations
ztran <- round2(r2z(cbind(r=cors$rho$list, cors$mcmc$HDI$rho, H1=H1s))) #ztransfrom stuff for BFs
rhos <- cbind(ztran,SE=(ztran[,'high']-ztran[,'low'])/4)#(qnorm(.975)*2)) #new SE transform
#BFs
BFs <- cbind(rhos[,F],BF=NA,RRl=NA,RRu=NA)
for(i in 1:nrow(rhos)){ # i<-1
BF <- bfrr(sample_mean=rhos[i,'r'],sample_se=rhos[i,'SE'],sample_df=nrow(cors$Mratio)-1,
model="normal", mean=0, sd=H1s[i], tail=1, criterion=3,
rr_interval=list(mean=c(0,0),sd=c(0,1)),precision=.01)
BFs[i,] <- c(BF$BF,BF$RR$sd)
}
output <- round2(cbind(r=cors$rho$list,
cors$mcmc$HDI$rho,
h1=rhos[,'H1'],
BFs))
#sort formatting issues with my Hmeta-d function
colnames(output)[colnames(output)%in%c('low','high')] <- c("lower","upper")
return(output)
}
#run
bf_h <- list(M_ratio = Hcor(c_Hcor_S0,rels_h[[1]]),
M_ratio_rS1 = Hcor(c_Hcor_S1,rels_h[[2]]),
M_ratio_rS2 = Hcor(c_Hcor_S2,rels_h[[3]]),
highest_mratio = Hcor(c_Hcor_S3,rels_h[[4]]))
############################################# Non-hierarchical Correlations ----
# Non-Hierarchical Correlations -----
# List variables to correlate
corList <- function(c_SDTs){
# datasets of variables to correlate
cor_vars <- lapply(var_names,function(x){ sapply(c_SDTs,function(y){y[,x]}) })
names(cor_vars) <- var_names
# Replace tasks for different analyses
cor_vars$highest_mratio <- cor_vars$M_ratio
cor_vars$highest_mratio[,c('gabor_2AFC','span_YN')] <- cor_vars$M_ratio_rS1[,c('gabor_2AFC','span_YN')]
cor_vars$highest_mratio[,'gabor_YN'] <- cor_vars$M_ratio_rS2[,'gabor_YN']
cor_vars$M_ratio_rS1[,AFC] <- cor_vars$M_ratio[,AFC] # 'No' for YN tasks only
cor_vars$M_ratio_rS2[,AFC] <- cor_vars$M_ratio[,AFC] # 'Yes' for YN tasks only
return(cor_vars)
}
# get main correlations
data_nh <- corList(c_SDTs)
list_nh <- lapply(data_nh,corr.test)
z_SE <- round2(1/sqrt(list_nh$M_ratio$n-3))
cor_nh <- lapply(list_nh,function(x){ cbind(x$ci[,1:3], se=z_SE) }) #x$se[lower.tri(x$se)]
# Non-Hierarchical Relibailities -----
# reliabilities
reliabilitiesNh <- function(split_SDT){
nh_even <- corList(split_SDT$even) #list vars to correlate
nh_odd <- corList(split_SDT$odd)
nh_cors <- mapply(corr.test,nh_even,nh_odd)['ci',] # correlate odd and even
allv <- expand.grid(tnames,tnames) # all possible combinations of vars
nh_rels <- lapply(nh_cors,function(x){ x[which(allv[,1]==allv[,2]),1:3]}) #reduce to reliabilities
nh_rels <- lapply(nh_rels,sb) #Spearman-Brown Adjust
lapply(nh_rels,round2) #round
}
#get reliabilities list
rels_nh <- reliabilitiesNh(split_SDT)
# Non-Hierarchical BFs -----
#Bayes Factors
bfsNh <- function(rels_nh,cor_nh){
#reliabilities to H1 #note these are sb adjusted above
h1_nh <- sapply(rels_nh,function(x){ (x[idx[,1],'r'] * x[idx[,2],'r']) **.5 /2 }) #combined reliabilities
#r to z transform
h1_nh <- r2z(h1_nh)
rz <- lapply(cor_nh,r2z)
# list
eff_nh <- lapply(1:length(cor_nh),function(x){cbind(r=rz[[x]][,'r'], #z transormed correlation
se=cor_nh[[x]][,'se'], #standard se
h1=h1_nh[,x])}) #combined reliabilities
names(eff_nh) <- names(cor_nh) #nicer names
#get bayes factors
lapply(names(eff_nh),function(x){ # x<-eff_nh[[1]]
eff_tab <- eff_nh[[x]]
BFs <- c()
for(i in 1:nrow(eff_tab)){ # i<-1
if(is.nan(eff_tab[i,'h1']) | eff_tab[i,'h1']<0){ # skip if H1 is NA or <0
BFs <- rbind(BFs,rep(NA,3))
next
}
#Bfs
BF <- bfrr(sample_mean=eff_tab[i,'r'], sample_se=eff_tab[i,'se'],
sample_df=nrow(c_SDTs$dots)-1, model="normal", mean=0,
sd=eff_tab[i,'h1'], tail=1, criterion=3,
rr_interval=list(mean=c(0,0),sd=c(-1,1)),precision=.01)
BFs <- rbind(BFs,c(BF=BF$BF,RR=BF$RR$sd))
}
colnames(BFs) <- c('BF','RRl','RRu')
cbind(cor_nh[[x]],round2(BFs)) #final tables
})
}
#get bayes factors
bf_nh <- bfsNh(rels_nh,cor_nh)
################################################################ Formatting ----
# Concatenate columns -----
matChars <- function(mat,cortype='r',err='CI',ntask=6){ # mat=bf_h
lapply(mat,function(x){ # x<-mat[[1]]
x <- round2(data.frame(x))
p <- paste0(cortype,'=',x$r,'\r',err,'=[',x$lower,', ',x$upper,']')
if('BF'%in%colnames(mat[[1]])){
x[is.na(x)] <- ''
p <- paste0(p,'\rBF=',x$BF,'\rRR=[',x$RRl,', ',x$RRu,']')
p <- gsub('\\rBF=\\rRR=\\[,\\s]','\r-',p)
}
return(p)
})
}
# Print as matrices -----
matify <- function(h_chars,nh_chars,r_chars){ #h_chars=h_list[[1]];nh_chars=nh_list[[1]];r_chars=r_list
ntask <- length(r_chars[[1]])
#Make mat
lapply(1:length(h_chars),function(x){ # x<-1
mat <- matrix(1,ntask,ntask)
for(i in 1:nrow(idx)){ #i<-6
mat[idx[i,1],idx[i,2]] <- nh_chars[[x]][i] #top
if(i<=ntask){mat[i,i] <- r_chars[[x]][i]} #diag
mat[idx[i,2],idx[i,1]] <- h_chars[[x]][i] #bottom
}
dimnames(mat) <- list(tnames,tnames)
write_excel_csv(data.frame(mat),paste0('csv_files/',names(h_chars)[x],'_mat.csv'))
return(mat)
})
}
#matrix has H on bottom, NH on top, both inside the
correlationMatrices <- function(bf_h,rels_h,bf_nh,rels_nh){
bf_h_chars <- matChars(bf_h,'\u03C1','HDI')
rels_h_chars <- matChars(rels_h,'\u03C1','HDI')
bf_nh_chars <- matChars(bf_nh,'r','CI')
rels_nh_chars <- matChars(rels_nh,'r','CI')
r_list <- lapply(1:4,function(x){paste0(rels_nh_chars[[x]],'\n\n',rels_h_chars[[x]])}) #mapply(paste0,nh_mats[[2]],h_mats[[2]])
mats <- matify(bf_h_chars,bf_nh_chars,r_list)
}
correlationMatrices(bf_h,rels_h,bf_nh,rels_nh)
lapply(names(bf_h),function(x){write.csv(bf_h[[x]],paste0('csv_files/',x,'_list.csv'))})
# Reliabilities barplot ----
# done here so to add in breath
#c_rels_S0 <- readRDS('rds_files/c_rels_S0.rds')
reliabilityPlot <- function(i_rels,h_rels){
rels_i <- i_rels[c('d1','meta_d','M_ratio'),]
rels_h <- c(sapply(h_rels$'20',function(x){x$rho$list}),breath=c_rels_S0$breath$rho$list)
rels_a <- t(rbind(rels_i,rels_h))
colnames(rels_a) <- c("d'","meta-d'","M-ratio","Hmeta-d")
jpeg('graphs/reliabilities.jpeg',height=200,width=200,units='mm',res=100,quality=200)
par(mar=rep(3,4))
barplot(rels_a,beside=T,col=c(1:6),main='Reliabilities',cex.axis=2,cex.names=2,cex.main=2)
legend('topleft',tnames,col=1:6,pch=15,text.font=2)
dev.off()
}
reliabilityPlot(i_rels,h_rels)
####################################################################### Fin ----
# End timer & save -----
save.image(file='gfactor.RData')
end_time <- Sys.time()-start_time
print(end_time)
#m_dir <- apply(rs_est,2,function(x){ifelse(x[1]>x[2],1,2)})
rs_samples <- lapply(group_rc,function(x){exp(x$samples)})
nsubj <- length(group_nrc[[1]]$observed_d1)
rg_est <- exp(sapply(group_nrc,function(x){x$group_means})['mu_logMratio',])
rs_est <- exp(sapply(group_rc,function(x){x$group_means})[c('mu_logMratio_rS1','mu_logMratio_rS2'),])
############################################################### Group-level ----
# Group-Level Hmeta-d ------
c_nrsxs <- readRDS('rds_files/c_nrsxs.rds')
#setup
mcmc_params <- list(response_conditional=0,estimate_dprime=0,rhat=1,parallel=1,
nchains=3,nadapt=1000,nburnin=1000,nsamples=10000,nthin=1)
# Response-general
#group_nrc <- apply(c_nrsxs,2,function(x){ fit_meta_d_mcmc_group(x[[1]],x[[2]],mcmc_params) })
#saveRDS(group_nrc,'rds_files/group_nrc.rds')
group_nrc <- readRDS('rds_files/group_nrc.rds')
# Response-Specific
mcmc_params$response_conditional <- 1
#group_rc <- apply(c_nrsxs,2,function(x){ fit_meta_d_mcmc_group(x[[1]],x[[2]],mcmc_params) })
#saveRDS(group_rc,'rds_files/group_rc.rds')
group_rc <- readRDS('rds_files/group_rc.rds')
# Correct HDIs: originally forgot to exp() the group-level results.
HDIs_nrc <- lapply(group_nrc,function(x){HPDinterval(as.mcmc(exp(x$samples)))})
# Analysis code for G-factor study by Max Lovell #
# Setup ----
# note any time consuming analyses have their outputs stored in rds files.
#make working dir same as script file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#load environment if code already run
if(file.exists('gfactor.RData')){
#load('gfactor.RData')
}
start_time <- Sys.time()
# Packages ----
list.of.packages <- c('jsonlite',  # ::fromJSON() for reding in raw data
'rjags',     # run Hmeta-d models (JAGS must be installed outside R)
'parallel',  # run JAGS in parallel
'stableGR',  # ::stable.GR() for improved Rhat
'beepr',     # ::beep() for alerts when code is done
'readr',     # ::write_excel_csv() for writing Rho character to csv
'devtools',  # ::install_github() as bfrr not working
'bfrr',      # ::bfrr() Bayes Factors and Robustness regions
'psych',     # ::corr.test() for non-H correlations
'NlcOptim',  # ::solnl() for Maxmimum Likelihood Estimation
'viridis',    # colour palette
'uaparserjs' # parse user agents
)
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
if('bfrr' %in% new.packages){ devtools::install_github("debruine/bfrr") }
lapply(list.of.packages, require, character.only = TRUE)
source("meta-d/fit_meta_d_MLE.R")
source("meta-d/fit_meta_d_mcmc.R")
source("meta-d/fit_meta_d_mcmc_group.R")
source("meta-d/fit_meta_d_mcmc_groupCorr.R")
# Helpers -----
idx <- t(combn(6,2))
# names
pnames <- c("TMS"="TMS-D", "SOW_F"="Observe 1st", "SOW_S"="Observe 2nd",
"acc"="Accuracy", "dp"="d'", "c"="c", "adj_dp"="Adj. d'",
"dp2"="Type-2 d'", "c2"="Type-2 c", "adj_dp2"="Adj. type-2 d'",
"adj_meta_d"="Adj. meta-d'", "H_meta_d"="Hmeta-d", "H_M_ratio"="HM-ratio",
"ln_M_ratio"="log(M-ratio)")
#Variables for correlations
var_names <- c('M_ratio','M_ratio_rS1','M_ratio_rS2')
tnames <- c("Dots","Gabor YN","Gabor 2AFC","Span YN","Span 2AFC","Breath")
AFC <- c('dots','gabor_2AFC','span_2AFC') #2AFC tasks
YN <- c('gabor_YN','span_YN','breath')
#Fisher's r<=>z transforms
r2z <- function(r){ .5*(log((1+r)/(1-r))) }
z2r <- function(z){ (exp(2*z)-1)/(exp(2*z)+1) }
# s-b adjust correlations
sb <- function(x){(2*x)/(1+x)}
# error calculation
se <- function(x,na.rm=F){
if(na.rm){x<-x[!is.na(x)]}
sd(x)/sqrt(length(x))
}
ci <- function(x){ se(x)*qnorm(.975) }
# Round function to stop R even rounding as we only need 2 d.p.
# https://www.r-bloggers.com/2023/04/rounding-in-r-common-data-wrangling-frustrations-and-workarounds-in-r-julia-and-python
# https://stackoverflow.com/questions/12688717/round-up-from-5/12688836#12688836
round2 <- function(x, digits = 2) {  # Function to always round 0.5 up
posneg <- sign(x)
z <- abs(x) * 10^digits
z <- z + 0.5
z <- trunc(z)
z <- z / 10^digits
z * posneg
}
###################################################################### Read ----
# Read data ----
# note putty must be installed for pscp to work
# replace square brackets: system('pscp -pw [password] [server space root]:[data folder]/*.json "C:\\Users\\[folder to download to]"')
readTasks <- function(tasks){
all_files <- list.files("data/") #list downloaded files
tasks_raw <- list()
for(t in task_names){ #t<-task_names[4]
task_files <- all_files[grep(t,all_files)] #list files for each task
task <- c()
for(f in task_files){ #f<-task_files[1] ;#loop through files
file <- fromJSON(paste0("data/",f)) # Read in raw datafile
if(length(file)==0){print(f) #print names of incorrect files
file.remove(paste0("data/",f)) #remove incorrect files
} else {
file$ID <- sub("\\D+","",f) # get ID
if(t=='survey'){ file <- data.frame(file) }
task <- rbind(task,file) # bind subj data to matrix
}
}
write.csv(data.frame(apply(task,2,as.character)),paste0('csv_files/',t,".csv"))#convert to character so commas are correct in CSV
tasks_raw <- c(tasks_raw,list(task)) # combine tasks into list
}
names(tasks_raw) <- task_names
return(tasks_raw)
}
task_names <- c("survey","dots","gabor","span","breath")
#tasks_raw <- readTasks(task_names)
#saveRDS(tasks_raw,'rds_files/tasks_raw.rds')
tasks_raw <- readRDS('rds_files/tasks_raw.rds')
# Dropouts ----
all_files <- list.files("data/") #list downloaded files
id_count <- table(gsub('\\D+','',all_files)) #count number of files for each person
#note if(length(file)==0){print(f);next} above removes empty datasets from the folder
valid_ids <- names(id_count[id_count==5]) # participants with full data sets
dropouts <- cbind( #count different number of dropouts
student_n = sum(nchar(names(id_count))==5),
known_n = sum(nchar(names(id_count))==6),
dropout_n = sum(id_count!=5),
protocol_n = sum(id_count==5),
dropout_rate = (sum(id_count!=5)/length(id_count))*100
)
# Check User Agents, Debugging ------
#user agents and ids
#srv <- tasks_raw$survey[,c('ID','user_agent')]
#uas <- data.frame(UAs$ID,ua_parse(UAs$user_agent))
#breath count
#br_count <- tapply(tasks_raw$breath,tasks_raw$breath$ID,nrow)
#br_n <- data.frame(br=br_count,ID=names(br_count))
#merge
#ua_br <- merge(uas,br_n,by.x='UAs.ID',by.y='ID')
#ua_br <- ua_br[order(ua_br$br, ua_br$userAgent),]
#write.csv(ua_br,'UAs_br_count.csv')
# Correct HDIs: originally forgot to exp() the group-level results.
HDIs_nrc <- lapply(group_nrc,function(x){HPDinterval(as.mcmc(exp(x$samples)))})
HDIs_rc <- lapply(group_rc,function(x){HPDinterval(as.mcmc(exp(x$samples)))})
HDIs <- Map(rbind,HDIs_nrc,HDIs_rc)
#correlate c and responses
c_resp_cor <- round2(mapply(function(x,y){corr.test(x$c1,y$response_pctg)$r},c_SDTs,c_resp))
nsubj <- length(group_nrc[[1]]$observed_d1)
rg_est <- exp(sapply(group_nrc,function(x){x$group_means})['mu_logMratio',])
rs_est <- exp(sapply(group_rc,function(x){x$group_means})[c('mu_logMratio_rS1','mu_logMratio_rS2'),])
#m_dir <- apply(rs_est,2,function(x){ifelse(x[1]>x[2],1,2)})
rs_samples <- lapply(group_rc,function(x){exp(x$samples)})
rs_samples
#m_dir <- apply(rs_est,2,function(x){ifelse(x[1]>x[2],1,2)})
group_rc$dots$samples[,2]
diff_samp <- lapply(group_rc,function(x){exp(x$samples[,2])-exp(x$samples[,1])})
diff_samp
diff_samp <- sapply(group_rc,function(x){exp(x$samples[,2])-exp(x$samples[,1])})
diff_samp
# Group-Level Bayes Factors ------
groupBFs <- function(){
nsubj <- length(group_nrc[[1]]$observed_d1)
rg_est <- exp(sapply(group_nrc,function(x){x$group_means})['mu_logMratio',])
rs_est <- exp(sapply(group_rc,function(x){x$group_means})[c('mu_logMratio_rS1','mu_logMratio_rS2'),])
#analysis of whichever was higher
#m_dir <- apply(rs_est,2,function(x){ifelse(x[1]>x[2],1,2)})
#rs_samples <- lapply(group_rc,function(x){exp(x$samples)})
#diff_samp <- mapply(function(x,y){x[,y]-x[,-y]},rs_samples,m_dir)
diff_samp <- sapply(group_rc,function(x){exp(x$samples[,2])-exp(x$samples[,1])})
g_BF <- round2(cbind(
Mean = apply(diff_samp,2,mean),
SE = apply(diff_samp,2,sd),
H1 = rg_est/2, BF=NA,RRl=NA,RRu=NA))
rownames(g_BF) <- tnames
for(i in 1:nrow(g_BF)){ #i<-1
BF <- bfrr(sample_mean=g_BF[i,'Mean'],sample_se=g_BF[i,'SE'],sample_df=nsubj-1,
model="normal", mean=0, sd=g_BF[i,'H1'], tail=2, criterion=3,
rr_interval=list(mean=c(0,0),sd=c(0,5),precision=.01))
g_BF[i,c('BF','RRl','RRu')] <- c(round2(BF$BF),BF$RR$sd)
}
g_BF[g_BF[,'BF']>1000,'BF'] <- format(g_BF[g_BF[,'BF']>1000,'BF'], scientific=T,digits=2)
g_BF[g_BF[,'RRu']==5,'RRu'] <- ">5"
g_BF[,'RRl'] <- paste0('[',g_BF[,'RRl'],', ',g_BF[,'RRu'],']')
g_BF <- g_BF[,colnames(g_BF)!='RRu']
write.csv(g_BF,'csv_files/group_BFs.csv')
return(g_BF)
}
group_BFs <- groupBFs()
